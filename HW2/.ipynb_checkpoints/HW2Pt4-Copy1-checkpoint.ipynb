{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a189cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac\\anaconda3\\envs\\CS273\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import os, glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99faec",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "CNN tuning: Focus on simulation setting 7 to optimize your CNN for improved \n",
    "classification performance on the test set. Generate an independent validation set of 1000 \n",
    "subjects to assist in tuning. Define a search space for the number of convolution layers, \n",
    "the width of the final fully connected layer, and the optimizer's learning rate. Conduct a \n",
    "grid search over the defined search space to identify the best hyperparameter \n",
    "combination. Report the search space, selected hyperparameters, and the classification \n",
    "accuracy for each combination tested.\n",
    "\n",
    "* Use model a base model.\n",
    "    * Remember only using data setting 7. [X]\n",
    "    * have only one train (n_i), one validation (1000), and one test set (1000) [X]\n",
    "    * number of convolution layers: 1, 2, 3, 4, 5\n",
    "    * Readjust model with different final fully connected layers: 8, 16, 32, 64, 128\n",
    "    * lr = 0.001, .01, .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc5aa726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateData(n, mu_c, mu_n):\n",
    "\n",
    "    y = np.random.choice([0, 1], size = n, p = [0.5, 0.5])\n",
    "    m_i = np.random.poisson(lam = mu_c, size = n) * y + np.random.poisson(lam = mu_n, size = n) * (1 - y)\n",
    "\n",
    "    simulated_data = np.zeros([n, 32, 32])\n",
    "    for i in range(n):\n",
    "        random_indices = np.random.choice(32 * 32, m_i[i], replace = False)\n",
    "        row_indices, col_indices = np.unravel_index(random_indices, (32, 32))\n",
    "        Bi = np.zeros([32, 32])\n",
    "        Bi[row_indices, col_indices] = 1\n",
    "        epsilon_i = np.random.normal(loc = 0, scale = np.sqrt(0.04), size = (32, 32))\n",
    "        simulated_data[i] = Bi + epsilon_i\n",
    "\n",
    "    return y, simulated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d419903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = simulateData(n = 200, mu_c = 5, mu_n = 30)\n",
    "y_val, X_val = simulateData(n = 1000, mu_c = 5, mu_n = 30)\n",
    "y_test, X_test = simulateData(n = 1000, mu_c = 5, mu_n = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1dd0b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m exampleImg \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m[\u001b[38;5;241m0\u001b[39m, :, :]\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m])\n\u001b[0;32m      2\u001b[0m exampleImg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(exampleImg)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      3\u001b[0m exampleImg\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "exampleImg = x_train[0, :, :].reshape([1, 1, 32, 32])\n",
    "exampleImg = torch.from_numpy(exampleImg).float()\n",
    "exampleImg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2182a9e",
   "metadata": {},
   "source": [
    "#### Model Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "150a27e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base model\n",
    "class BaseCNN(torch.nn.Module):\n",
    "    def __init__(self, num_conv_layers, final_fc_width):\n",
    "        super(BaseCNN, self).__init__()\n",
    "        \n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        \n",
    "        # Define convolutional layers dynamically based on num_conv_layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = 1  #  input channels = 1\n",
    "        out_channels = 2  # Initial output channels\n",
    "        for i in range(num_conv_layers):\n",
    "            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "            self.conv_layers.append(nn.ReLU())\n",
    "            self.conv_layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "            # Update in_channels and out_channels for the next layer\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2  # Double the channels for each subsequent layer\n",
    "        \n",
    "        # Calculate the input size for the fully connected layer\n",
    "        conv_output_size = self._get_conv_output_size()\n",
    "        \n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc = nn.Linear(conv_output_size, final_fc_width)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(final_fc_width, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "        \n",
    "        # Flatten the output from convolutional layers\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Forward pass through fully connected layers\n",
    "        x = self.relu(self.fc(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        # Method to calculate the output size of the convolutional layers\n",
    "        x = torch.rand(1, 1, 32, 32)  # Assuming input size is 28x28\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "        return x.view(1, -1).size(1)\n",
    "    \n",
    "# Create an instance of MyModel\n",
    "# model = BaseCNN(num_conv_layers = 3, final_fc_width = 10)\n",
    "# model(exampleImg)\n",
    "\n",
    "# Create an instance of NeuralNetClassifier\n",
    "net = NeuralNetClassifier(\n",
    "    BaseCNN,\n",
    "    max_epochs=200,\n",
    "    lr=0.001,\n",
    "    criterion=torchnn.BCELoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    iterator_train__shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3365d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class dataSetPytorch(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.from_numpy(x.reshape([-1, 1, 32, 32])).float()\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "datasetSetting_train = dataSetPytorch(x_train, y_train)\n",
    "dataLoader_train = DataLoader(datasetSetting_train, batch_size=25, shuffle = True)\n",
    "\n",
    "datasetSetting_val = dataSetPytorch(x_val, y_val)\n",
    "dataLoader_val = DataLoader(datasetSetting_val, batch_size=25, shuffle = True)\n",
    "\n",
    "datasetSetting_test = dataSetPytorch(x_test, y_test)\n",
    "dataLoader_test = DataLoader(datasetSetting_test, batch_size=25, shuffle = True)\n",
    "\n",
    "\n",
    "len(dataLoader_val.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2402876",
   "metadata": {},
   "source": [
    "### Train and test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3249508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "    return\n",
    "\n",
    "def saveModel(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac7c9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(BaseCNN, X_train, X_val, X_test, y_train, y_val, y_test, param_dict, num_epochs = 200):\n",
    "    model = BaseCNN(num_conv_layers = param_dict[\"num_conv_layers\"], final_fc_width = param_dict[\"final_fc_width\"])\n",
    "    \n",
    "    datasetSetting_train = dataSetPytorch(X_train, y_train)\n",
    "    train_dl = DataLoader(datasetSetting_train, batch_size=25, shuffle = True)\n",
    "\n",
    "    datasetSetting_val = dataSetPytorch(X_val, y_val)\n",
    "    valid_dl = DataLoader(datasetSetting_val, batch_size=25, shuffle = True)\n",
    "\n",
    "    datasetSetting_test = dataSetPytorch(X_test, y_test)\n",
    "    test_dl = DataLoader(datasetSetting_test, batch_size=25, shuffle = True)\n",
    "    \n",
    "    # reinitialize weights!\n",
    "    reset_weights(model)\n",
    "    \n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = param_dict[\"learningRate\"])\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs \n",
    "\n",
    "    best_loss = torch.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            pred = model(x_batch)[:, 0]\n",
    "            loss = loss_fn(pred, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item() * y_batch.size(0)\n",
    "\n",
    "            is_correct = ((pred >= 0.5).float() == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum()\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                pred = model(x_batch)[:, 0]\n",
    "                loss = loss_fn(pred, y_batch.float())\n",
    "                loss_hist_valid[epoch] += loss.item() * y_batch.size(0)\n",
    "\n",
    "                is_correct = ((pred >= 0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum()\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "\n",
    "        if (best_loss > loss_hist_valid[epoch]):\n",
    "            saveModel(model, \"bestModel.pth\")\n",
    "            best_loss = loss_hist_valid[epoch]\n",
    "\n",
    "    # model is done training, now evaluate the test accuracy score here.\n",
    "    modelWeightParams = torch.load(\"bestModel.pth\")\n",
    "    model.load_state_dict(modelWeightParams)\n",
    "    accuracy_test = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_dl:\n",
    "            pred = model(x_batch)[:, 0]\n",
    "            is_correct = ((pred >= 0.5).float() == y_batch).float()\n",
    "            accuracy_test += is_correct.sum()   \n",
    "    accuracy_test /= len(test_dl.dataset)\n",
    "    \n",
    "    return accuracy_test.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8210434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter grid:\n",
    "# param_grid = {\n",
    "#     'final_fc_width': [8, 16, 32, 64, 128],\n",
    "#     'num_conv_layers': [1, 2, 3, 4, 5],\n",
    "#     'learningRate': [0.001, 0.005, 0.01, .1],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'final_fc_width': [8, 16],\n",
    "    'num_conv_layers': [1, 2],\n",
    "    'learningRate': [0.001, 0.005],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21dc6ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'final_fc_width' for estimator <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n  module=<class '__main__.BaseCNN'>,\n). Valid parameters are: ['module', 'criterion', 'optimizer', 'lr', 'max_epochs', 'batch_size', 'iterator_train', 'iterator_valid', 'dataset', 'train_split', 'callbacks', 'predict_nonlinearity', 'warm_start', 'verbose', 'device', 'compile', 'use_caching', '_params_to_validate', 'classes'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [66]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mnet, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39mcustom_score)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:674\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    672\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 674\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcloned_parameters)\n\u001b[0;32m    676\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    678\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\skorch\\net.py:2084\u001b[0m, in \u001b[0;36mNeuralNet.set_params\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   2081\u001b[0m         normal_params[key] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_virtual_params(virtual_params)\n\u001b[1;32m-> 2084\u001b[0m BaseEstimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnormal_params)\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m special_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2087\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CS273\\lib\\site-packages\\sklearn\\base.py:246\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[0;32m    245\u001b[0m     local_valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m     )\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[0;32m    252\u001b[0m     nested_params[key][sub_key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'final_fc_width' for estimator <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n  module=<class '__main__.BaseCNN'>,\n). Valid parameters are: ['module', 'criterion', 'optimizer', 'lr', 'max_epochs', 'batch_size', 'iterator_train', 'iterator_valid', 'dataset', 'train_split', 'callbacks', 'predict_nonlinearity', 'warm_start', 'verbose', 'device', 'compile', 'use_caching', '_params_to_validate', 'classes']."
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=net, param_grid=param_grid, scoring=custom_score)\n",
    "grid_search.fit(X_train, y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1444a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Access best performing model and score\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best model score: {best_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
